<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Test | SMT-COMP 2024</title>
<link rel=stylesheet href=/2024/css/main.min.b9e488ebfe57109c735cb140cad148d852142092b21c3f0582438f55ae663090.css integrity="sha256-7ZcKqe0X+fj1KqWSlgXxDX02/sxy8/y/JTUKL+J+Yq4=" crossorigin=anonymous><script src=/2024/js/main.23cd0c7d837263b9eaeb96ee2d9ccfa2969daa3fa00fa1c1fe8701a9b87251a1.js integrity="sha256-I80MfYNyY7nq65buLZzPopadqj+gD6HB/ocBqbhyUaE=" crossorigin=anonymous></script></head><body><div class=wrapper><header><h1><a href=/>SMT-COMP 2024</a></h1><p>The International Satisfiability Modulo Theories (SMT) Competition.</p><p class=view><a class=hl href=https://github.com/smt-comp>GitHub</a></p><nav><a class=hl href=/2024/>Home</a><br><a class=hl href=/2024/introduction/>Introduction</a><br><a class=hl href=/2024/benchmark_submission/>Benchmark Submission</a><br><a class=hl href=/2024/publications/>Publications</a><br><a class=hl href=https://smtlib.cs.uiowa.edu/>SMT-LIB</a><br><a class=hl href=/2024/previous/>Previous Editions</a><br></nav><p class=view><h3><a href>SMT-COMP 2024</a></h3><nav><a class=hl href=/2024/results/>Results</a><br><a class=hl href=/2024/rules.pdf>Rules</a><br><a class=hl href=specs>Specs</a><br><a class=hl href=/2024/solver_submission/>Solver Submission</a><br><a class=hl href=/2024/model/>Model Validation Track</a><br><a class=hl href=/2024/parallel_cloud/>Parallel & Cloud Tracks</a><br><a class=hl href=/2024/model_validation/>Validation of the Models</a><br><a class=hl href=/2024/participants/>Participants</a><br></nav></header><section><h1>Test</h1><p>Do you have interesting or hard benchmarks that can be made public?
Want the world’s best SMT solvers to compete to solve your problems?
Submit your benchmarks to SMT-LIB and SMT-COMP!</p><p>Please let us know as soon as possible if you are considering
submitting benchmarks, even if the material is not quite ready. We
will work in close cooperation with the SMT-LIB maintainers to
integrate such benchmarks into SMT-LIB. The deadline for submission
of new benchmarks to be used in the 2023 competition is March 31, 2023.</p><p>If you have large complex benchmarks that are important to you and
unsolved within some reasonable time limit, we are especially
interested to see them. We will have again this year a parallel and a
cloud track where solvers can use the combined power of multiple cores
or machines to solve a single benchmark. We would particularly like
benchmarks that come with a description of why they are difficult and
important. Of course, new challenging benchmarks are always
appreciated.</p><p>For your submission please follow
<a href=https://smt-comp.github.io/benchmark_submission.html>these guidelines</a>.</p><p>Note that this is a different (but improved) process from previous
years. If you have questions you can contact us or the SMT-LIB
maintainers (contact information in the link above).</p><p>Sincerely,</p><p>The organizing team</p><ul><li>François Bobot (chair), CEA List, France</li><li>Martin Bromberger, MPI for Informatics, Germany</li><li>Jochen Hoenicke, Certora, Israel</li></ul></section><footer></footer></div></body></html>
