<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Benchmark Submission | SMT-COMP 2024</title>
<link rel=stylesheet href=/2024/css/main.min.b9e488ebfe57109c735cb140cad148d852142092b21c3f0582438f55ae663090.css integrity="sha256-7ZcKqe0X+fj1KqWSlgXxDX02/sxy8/y/JTUKL+J+Yq4=" crossorigin=anonymous><script src=/2024/js/main.23cd0c7d837263b9eaeb96ee2d9ccfa2969daa3fa00fa1c1fe8701a9b87251a1.js integrity="sha256-I80MfYNyY7nq65buLZzPopadqj+gD6HB/ocBqbhyUaE=" crossorigin=anonymous></script></head><body><div class=wrapper><header><h1><a href=/>SMT-COMP 2024</a></h1><p>The International Satisfiability Modulo Theories (SMT) Competition.</p><p class=view><a class=hl href=https://github.com/smt-comp>GitHub</a></p><nav><a class=hl href=/2024/>Home</a><br><a class=hl href=/2024/introduction/>Introduction</a><br><a class=hl aria-current=page class=active href=/2024/benchmark_submission/>Benchmark Submission</a><br><a class=hl href=/2024/publications/>Publications</a><br><a class=hl href=https://smtlib.cs.uiowa.edu/>SMT-LIB</a><br><a class=hl href=/2024/previous/>Previous Editions</a><br></nav><p class=view><h3><a href>SMT-COMP 2024</a></h3><nav><a class=hl href=/2024/results/>Results</a><br><a class=hl href=/2024/rules.pdf>Rules</a><br><a class=hl href=specs>Specs</a><br><a class=hl href=/2024/solver_submission/>Solver Submission</a><br><a class=hl href=/2024/model/>Model Validation Track</a><br><a class=hl href=/2024/parallel_cloud/>Parallel & Cloud Tracks</a><br><a class=hl href=/2024/model_validation/>Validation of the Models</a><br><a class=hl href=/2024/participants/>Participants</a><br></nav></header><section><h1>Benchmark Submission</h1><h2 id=benchmark-submission>Benchmark submission</h2><p>To submit new benchmarks, please follow the detailed instructions available at
<a href=https://github.com/SMT-LIB/benchmark-submission>the SMT-LIB benchmark submission
repository</a>.</p><p>We encourage to distribute benchmarks under the Creative Commons Attribution 4.0
International License, but submitters can specify their own licence in the
benchmark itself using the <code>(set-info :license "licence string")</code> command.</p><p>If you have any questions please contact one of the SMT-LIB maintainers
[1]. Note that the people maintaining the SMT-LIB benchmarks are not in general
the same as the ones organizing the competition.</p><ol><li>The SMT-LIB benchmark collection is co-managed by</li></ol><ul><li><a href=http://www.cs.stanford.edu/~barrett>Clark Barrett</a>, <a href=mailto:barrett@cs.stanford.edu>barrett@cs.stanford.edu</a></li><li><a href=https://members.loria.fr/PFontaine/>Pascal Fontaine</a>, <a href=mailto:pascal.fontaine@uliege.be>pascal.fontaine@uliege.be</a></li><li><a href=https://cs.stanford.edu/~niemetz/>Aina Niemetz</a>, <a href=mailto:niemetz@cs.stanford.edu>niemetz@cs.stanford.edu</a></li><li><a href=https://cs.stanford.edu/~preiner/>Mathias Preiner</a>, <a href=mailto:preiner@cs.stanford.edu>preiner@cs.stanford.edu</a></li><li><a href=https://schurr.io/>Hans-JÃ¶rg Schurr</a>, <a href=mailto:hans-jorg.schurr@inria.fr>hans-jorg.schurr@inria.fr</a></li></ul></section><footer></footer></div></body></html>
