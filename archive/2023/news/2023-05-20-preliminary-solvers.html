<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Preliminary Solvers | SMT-COMP</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Preliminary Solvers" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="List of Preliminary Solvers" />
<meta property="og:description" content="List of Preliminary Solvers" />
<link rel="canonical" href="https://smt-comp.github.io/2023/news/2023-05-20-preliminary-solvers" />
<meta property="og:url" content="https://smt-comp.github.io/2023/news/2023-05-20-preliminary-solvers" />
<meta property="og:site_name" content="SMT-COMP" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-05-20T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Preliminary Solvers" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-05-20T00:00:00+00:00","datePublished":"2023-05-20T00:00:00+00:00","description":"List of Preliminary Solvers","headline":"Preliminary Solvers","mainEntityOfPage":{"@type":"WebPage","@id":"https://smt-comp.github.io/2023/news/2023-05-20-preliminary-solvers"},"url":"https://smt-comp.github.io/2023/news/2023-05-20-preliminary-solvers"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css?v=ca87ca498acb8424db393bc72e2497c3e747f945">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <style> a { color: #6000ff; } </style>
  </head>
  <body>
    <div class="wrapper">
        <header>
  <h1>
    <a href="/">SMT-COMP</a>
  </h1>

  

  <p>The International Satisfiability Modulo Theories (SMT) Competition.</p>

  <p class="view">
    <a class="hl" href="https://github.com/smt-comp"><b>GitHub</b></a>
  </p>
  <p class="view">
    <a href="/index.html"><b>Home</b></a><br/>
    <a href="/introduction.html"><b>Introduction</b></a><br/>
    <a href="/benchmark_submission.html"><b>Benchmark Submission</b></a><br/>
    <a href="/publications.html"><b>Publications</b></a><br/>
    <a class="hl" href="https://smtlib.cs.uiowa.edu/"><b>SMT-LIB</b></a></br>
    <a class="hl" href="/previous.html"><b>Previous Editions</b></a></br>
  </p>
  <p class="view">
    <h3><a href="/2023/">SMT-COMP 2023</a>
    </h3>
    <a href="/2023/rules.pdf"><b>Rules</b></a><br/><a href="/2023/benchmarks.html"><b>Benchmarks</b></a><br/><a href="/2023/specs.html"><b>Specs</b></a><br/><a href="/2023/model.html"><b>Model Validation Track</b></a><br/><a href="/2023/proof-track.html"><b>Proof Exhibition Track</b></a><br/><a href="/2023/parallel-and-cloud-tracks.html"><b>Parallel & Cloud Tracks</b></a><br/><a href="/2023/participants.html"><b>Participants</b></a><br/><a href="/2023/results.html"><b>Results</b></a><br/><a href="/2023/stats.html"><b>Statistics</b></a><br/><a href="/2023/comparisons.html"><b>Comparisons</b></a><br/><a href="/2023/slides.html"><b>Slides</b></a><br/>
  </p>

  
</header>


      <section>

<h2>Preliminary Solvers </h2>
<p>20 May 2023

<h1 id="list-of-preliminary-solvers">List of Preliminary Solvers</h1>

<p>The <a href="/2023/participants.html">list of submitted solvers</a> is online now.  If you submitted a solver, please check
that your solver was added to the intended tracks and divisions and check the other info
we have. Note that there are a few new logics this year.</p>

<h2 id="starexec-test-runs">StarExec Test Runs</h2>

<p>We have run <a href="https://www.starexec.org/starexec/secure/explore/spaces.jsp?id=543250">Test Jobs</a> on StarExec
with the submitted solvers.  Please check if the result from your solver are as expected.
You should check the summary and you can download the job output and
check for suspicious error messages for your solvers.  In particular
if your solved count is 0.  We only ran a few benchmarks per logic for
testing and only with a 2 minute timeout.  I suspect some of the
solvers still have problems in the starexec environment.</p>

<p>Note that the scoring is not always correct. The incremental job
cannot be scored by starexec, so itâ€™s normal that the summary shows 0
solved.  For this job you have to check the output, or download the
Job Info table.  For the other tracks, the scoring may also be wrong
if the benchmark does not have a known status.</p>

<p>You can download the Job Info table which contains a CSV file with all
benchmark/solver pairs, the expected result and the starexec result.
The Job output file contains all outputs for all runs including error
messages.</p>

<p>If your solver has problems in the StarExec environment, you can use
the <a href="https://www.starexec.org/vmimage/">StarExec VM image</a> to debug
any problems.  You can also use this to compile your solver to ensure
it is compatible with the glibc version.  Alternatively use static
binaries or a CentOS-7 docker image for compilation.</p>


</p>

      </section>
      <footer>
        <!--

<p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
-->

      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>

